{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fde5398-9606-4a2f-984e-f602528dbcac",
   "metadata": {},
   "source": [
    "# Yash Meshram\n",
    "# Computer Vision & Internet of Things\n",
    "# The Sparks Foundation\n",
    "#\n",
    "## Task : Detection of face mask\n",
    "#\n",
    "## Testing the model on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45c39f12-27c2-47ca-8f6d-7d49b1cc21bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27f5a830-445d-461f-a2b9-0d31efb76e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "prototxtPath = os.path.sep.join([r'/home/yash-meshram/Documents/GitHub/mask-detection/face_detector/', 'deploy.prototxt'])\n",
    "weightsPath = os.path.sep.join([r'/home/yash-meshram/Documents/GitHub/mask-detection/face_detector', 'res10_300x300_ssd_iter_140000.caffemodel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2484e9dd-db0a-4b02-a76a-6309d9ff0c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/yash-meshram/Documents/GitHub/mask-detection/face_detector//deploy.prototxt'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prototxtPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46ac2c38-d770-4a44-a3e4-2a644cea5d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/yash-meshram/Documents/GitHub/mask-detection/face_detector/res10_300x300_ssd_iter_140000.caffemodel'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weightsPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9ee5c0c-8e80-4bdf-8bb4-af413d44d901",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNet(prototxtPath, weightsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "883f9546-6595-46b3-b8b0-9648b3f84128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dnn_Net 0x7ff108406a50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90b0a911-8064-4146-989f-b353fc6dbb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(r'/home/yash-meshram/Documents/GitHub/mask-detection/mobilenet_v2.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3554c7aa-0fa8-4706-b943-94b5d3e33bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take image and convert it to array---imread()\n",
    "image = cv2.imread(r'/home/yash-meshram/Documents/GitHub/mask-detection/test_image/example_01.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88f5c6d9-1988-422c-bb28-2657d30481a3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[186, 183, 145],\n",
       "        [186, 184, 144],\n",
       "        [186, 184, 144],\n",
       "        ...,\n",
       "        [223, 220, 215],\n",
       "        [223, 220, 215],\n",
       "        [223, 220, 215]],\n",
       "\n",
       "       [[184, 183, 145],\n",
       "        [184, 183, 145],\n",
       "        [184, 183, 145],\n",
       "        ...,\n",
       "        [223, 220, 215],\n",
       "        [223, 220, 215],\n",
       "        [223, 220, 215]],\n",
       "\n",
       "       [[182, 181, 146],\n",
       "        [182, 181, 146],\n",
       "        [183, 182, 144],\n",
       "        ...,\n",
       "        [223, 220, 215],\n",
       "        [223, 220, 215],\n",
       "        [223, 220, 215]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 90,  87,  77],\n",
       "        [ 90,  87,  77],\n",
       "        [ 91,  88,  78],\n",
       "        ...,\n",
       "        [106, 102,  96],\n",
       "        [106, 102,  96],\n",
       "        [106, 102,  96]],\n",
       "\n",
       "       [[ 90,  87,  77],\n",
       "        [ 91,  88,  78],\n",
       "        [ 91,  88,  78],\n",
       "        ...,\n",
       "        [105, 101,  95],\n",
       "        [105, 101,  95],\n",
       "        [105, 101,  95]],\n",
       "\n",
       "       [[ 90,  87,  77],\n",
       "        [ 91,  88,  78],\n",
       "        [ 91,  88,  78],\n",
       "        ...,\n",
       "        [104, 100,  94],\n",
       "        [104, 100,  94],\n",
       "        [104, 100,  94]]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e94f70e-a54c-4d56-b067-f414595b7cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 600, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e58d1299-5283-4280-ab7f-a769de368348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 600)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(h, w) = image.shape[:2]\n",
    "\n",
    "(h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97abd16a-822d-4adb-8cd0-e041317f7c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = cv2.dnn.blobFromImage(image, 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "# 1.0 is the scale factor. we are not going to scale it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0067af08-31bc-4f12-84f6-a42324049491",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 81.,  81.,  76., ..., 119., 119., 119.],\n",
       "         [ 78.,  79.,  81., ..., 119., 119., 119.],\n",
       "         [ 68.,  70.,  75., ..., 118., 118., 118.],\n",
       "         ...,\n",
       "         [-13., -13., -11., ...,  -1.,   1.,   2.],\n",
       "         [-14., -13., -15., ...,   0.,   2.,   2.],\n",
       "         [-14., -13., -14., ...,  -2.,   0.,   0.]],\n",
       "\n",
       "        [[  6.,   7.,   1., ...,  43.,  43.,  43.],\n",
       "         [  4.,   5.,   6., ...,  43.,  43.,  43.],\n",
       "         [ -5.,  -2.,   0., ...,  42.,  42.,  42.],\n",
       "         ...,\n",
       "         [-89., -89., -86., ..., -76., -76., -74.],\n",
       "         [-90., -89., -90., ..., -74., -75., -75.],\n",
       "         [-90., -89., -90., ..., -76., -77., -77.]],\n",
       "\n",
       "        [[ 22.,  21.,  13., ...,  92.,  92.,  92.],\n",
       "         [ 23.,  21.,  20., ...,  92.,  92.,  92.],\n",
       "         [ 18.,  19.,  16., ...,  91.,  91.,  91.],\n",
       "         ...,\n",
       "         [-45., -45., -42., ..., -33., -28., -26.],\n",
       "         [-46., -45., -46., ..., -33., -27., -27.],\n",
       "         [-46., -45., -45., ..., -35., -29., -29.]]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e13e6ffa-0630-4184-a3c6-51dd311db4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 300, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f3f7051-0e7d-4576-9e9c-ee775dd42bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.setInput(blob)\n",
    "detections = net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cde7e5e-1920-4de0-b4ca-50a13d6045a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.        , 1.        , 0.9984427 , ..., 0.12488028,\n",
       "          0.6709176 , 0.3542412 ],\n",
       "         [0.        , 1.        , 0.12920395, ..., 3.9990287 ,\n",
       "          4.8382664 , 4.984081  ],\n",
       "         [0.        , 1.        , 0.12446587, ..., 3.994579  ,\n",
       "          0.85450625, 4.978922  ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]]]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections    # this is the arry of the face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbd6d927-de19-43aa-9ea7-a6a5b416edac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 200, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c61036c7-f2da-4462-98bb-a059ad5e61ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the detections\n",
    "\n",
    "for i in range(0, detections.shape[2]):\n",
    "    confidence = detections[0, 0, i, 2]\n",
    "    \n",
    "    if confidence > 0.5:\n",
    "        # we need the x and y co-ordinates\n",
    "        box = detections[0, 0, i, 3:7]*np.array([w, h, w, h])\n",
    "        (startX, startY, endX, endY) = box.astype('int')\n",
    "        \n",
    "        # we need to ensure that the bounding boxes fall within the dimensions of the frame\n",
    "        (startX, startY) = (max(0, startX), max(0, startY))\n",
    "        (endX, endY) = (min(w-1, endX), min(h-1, endY))\n",
    "        \n",
    "        # extract the face ROI, convert it from BGR to RGB channel\n",
    "        # resize it to (224, 224) and preprocess it\n",
    "        \n",
    "        face = image[startY:endY, startX:endX]\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "        face = cv2.resize(face, (224, 224))\n",
    "        face = img_to_array(face)\n",
    "        face = preprocess_input(face)\n",
    "        face = np.expand_dims(face, axis = 0)\n",
    "        \n",
    "        (mask, withoutMask) = model.predict(face)[0]\n",
    "        \n",
    "        # determine the class label and color we will use to draw the bounding box and text\n",
    "        label = 'Mask' if mask > withoutMask else 'No Mask'\n",
    "        color = (0, 255, 0) if label == 'Mask' else (0, 0, 255)\n",
    "        \n",
    "        # lets include teh probability of teh label\n",
    "        label = '{} : {:.2f}%'.format(label, max(mask, withoutMask)*100)\n",
    "        \n",
    "        #display the label and the bounding boxes\n",
    "        cv2.putText(image, label, (startX, startY-10), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    "        cv2.rectangle(image, (startX, startY), (endX, endY), color, 2)\n",
    "        \n",
    "cv2.imshow('OutPut', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97d4f44-1e96-4589-8134-1f30a7f77e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c95de3-5bf2-48e9-9da2-f5a4b3453179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
